The head of Instagram has become the first technology boss to back a statutory duty of care to protect children from online harms, as he announced a ban on all graphic self-harm images on his website. In an exclusive interview with The Daily Telegraph, Adam Mosseri admitted the social media company had spent 10 years focusing on the "good" that comes out of connecting people while neglecting the "risks". As he backed the newspaper's campaign, he said it was time for the social media site, which is owned by Facebook, to take "responsibility" and act quickly against online harms. "I accept that we have room to improve and we have a responsibility to improve," he said. Mosseri yesterday met Matt Hancock, the Health Secretary, who last month wrote to social media firms including Instagram urging them to "step up and purge suicide and self-harm content once and for all". After the meeting, Hancock welcomed the Instagram move as "an important change", adding: "We are pushing for a duty of care for users of social media, particularly children. That duty is something that we're looking into as part of a White Paper which will be published by the Government." Asked if he backed a statutory duty of care, Mosseri, who has held senior posts at Facebook and Instagram, said: "I support that as a concept. We have a responsibility to not only create value for the people who use our platform but also to keep people safe. "That idea sounds very much in line with the responsibility to keep people safe. What that looks like is a decision for policymakers to make." The Telegraph's campaign for a statutory duty of care is backed by the Children's Commissioner, the NSPCC, the Commons science and technology select committee, the Labour Party, child and legal experts. Yesterday, Dame Sally Davies, the Chief Medical Officer, also backed a duty of care, and said tech companies "must make more effort to keep their users safe". The Government is drawing up new laws on social media modelled on a statutory duty of care, The Telegraph disclosed last week. The White Paper will create a regulator to police tech companies' ability to protect children from a specified list of online harms. Under the measures announced by Instagram, self-harm terms and content will also be removed from search listings, hashtags and account recommendations to make it harder for users to find such material. "If there is self-harm-related content, even if it's admission orientated, maybe someone has a picture of a scar and says 'I am 30 days clean', that's going to be staying on the platform - but it's going to be much more difficult to find," Mosseri said. He said Instagram was also developing technology to blur remaining self-harm content and put it behind a privacy screen so people did not accidentally find it and view it. It is also looking to increase the help it provides for self-harmers who use Instagram to share their experience. He said he had acted after being "overwhelmed" by the death of Molly, who took her life after viewing self-harm images online. Her father, Ian, said Instagram "helped kill my daughter". Asked how he felt when seeing Molly's father blame Instagram for his daughter's death, he said: "It was overwhelming. It's the kind of thing that hits you in the chest and sticks with you. "Asked why it had taken Instagram so long to tackle self-harm and to act only after the publicity surrounding Molly's death, he said: "We have not been as focused as we should have been on the effects of graphic imagery of anyone looking at content. That is something that we are looking to correct, and correct quickly. It's unfortunate it took the last few weeks for us to realise that. It's now our responsibility to address that issue as quickly as we can. "So for the last few weeks, it has been my focus to try to figure out how to address the issues. I am here [in the UK] in person, because it is important to me, but it hit me hard." Mosseri added: "I do want to be careful, because there is a tension between wanting to act and act quickly and the need to act responsibly. For instance, I don't want to do anything that will unintentionally stigmatise any sort of mental health issues. I don't want to do anything that will put a vulnerable person in a place where they feel unsupported or ashamed if we take that content down." There is a tension between speed and responsibility. We are trying to figure out how to navigate that." Yesterday Mosseri also met Jeremy Wright, the Culture Secretary, who is to publish in the next month plans for laws to regulate social media. It is expected to include a regulator with powers to force companies to remove illegal material such as violence and child abuse within fixed time periods and to purge content such as cyberbullying and self-harm imagery. - The Daily Telegraph